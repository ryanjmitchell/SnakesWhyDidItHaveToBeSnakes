{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration & Data Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is GIS really *the best*?\n",
    "\n",
    "### Part 1\n",
    "Given a file called `GIS_is_the_best.txt`, open that file and count the **total** number of words in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28177\n"
     ]
    }
   ],
   "source": [
    "z = 0\n",
    "\n",
    "#First, I need to open the file\n",
    "file = open('GIS_is_the_best.txt', 'r')\n",
    "\n",
    "#Now I need to read it...\n",
    "text = file.read()\n",
    "for i in text.split():\n",
    "    z +=1\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "What the most common word in that file is. This is a fairly fundamental task of parsing data.\n",
    "\n",
    "Note: capitalization doesn't matter. So, GIS, gis, and Gis should all be counted the same. Similarly, Geospatial and geospatial would be the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geographic 7545\n",
      "information 7545\n"
     ]
    }
   ],
   "source": [
    "# open file\n",
    "file = open('GIS_is_the_best.txt', 'r')\n",
    "wordcount={}\n",
    "    # lower case, & split into list\n",
    "for word in file.read().lower().split():\n",
    "    if word not in wordcount:\n",
    "        # add  word to wordCounter dictionary\n",
    "        wordcount[word] = 1\n",
    "    else:\n",
    "        # update count if word in dictionary\n",
    "        wordcount[word] += 1\n",
    "x = 0\n",
    "for word in wordcount:\n",
    "    if wordcount[word] >x:\n",
    "        y = word\n",
    "        x = wordcount[word]\n",
    "    elif wordcount[word] ==x:\n",
    "        p = word\n",
    "        q = wordcount [word]\n",
    "# print words and count\n",
    "'''for key in wordcount.keys():\n",
    "  print (\"%s %s \" %(key , wordcount[key]))'''\n",
    "if x > q:\n",
    "    print(y,x)\n",
    "if x == q:\n",
    "    print(y,x)\n",
    "    print(p,q)\n",
    "file.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A love of Lovecraft\n",
    "\n",
    "Given a .txt copy of *The Shunned House*\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Count the **number of unique words** in the text. \n",
    "A few directions:\n",
    "1. Case **does not** matter - so 'Whisker' should be the same as 'whisker.'\n",
    "2. Make sure you strip out punctuation - otherwise 'whisker?' and 'whisker!' will come back as different words.\n",
    "3. Plurals are different words - 'whiskers' and 'whisker' count separately.\n",
    "\n",
    "A few hints:\n",
    "1. One way to do this would be to create a dictionary of each word and then check the dictionaries length.\n",
    "2. You should get around 3,000 words depending on what assumptions you bake into this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2994\n"
     ]
    }
   ],
   "source": [
    "# dictionary\n",
    "wordcount = {}\n",
    "# open file\n",
    "with open('shunned_house.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "# remove punc\n",
    "for char in '.,?!\":;-_%&*$':\n",
    "    text = text.replace(char,' ')\n",
    "# lower, split, & count\n",
    "for word in text.lower().split():\n",
    "    if word in wordcount:\n",
    "        wordcount[word] += 1\n",
    "    else:\n",
    "        wordcount[word] = 1\n",
    "\n",
    "print(len(wordcount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Excluding prepositions ('from,' 'the,' 'an', 'with', 'a', etc.) what are the five most frequently used words in *The Shunned House* and how many times does each appear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 which\n",
      "58 house\n",
      "42 street\n",
      "31 harris\n",
      "30 there\n"
     ]
    }
   ],
   "source": [
    "# dictionary\n",
    "wordcount = {}\n",
    "prepositions = ['from','the','an','with','a','that','in','to']\n",
    "# open file\n",
    "with open('shunned_house.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "# remove punc\n",
    "    for char in '.,?!\":;-_%&*$':\n",
    "        text = text.replace(char,' ')\n",
    "# lower, split, & count\n",
    "    for word in text.lower().split():\n",
    "        if len(word) > 3 and word in wordcount:\n",
    "            wordcount[word] += 1\n",
    "        elif word not in prepositions:\n",
    "            wordcount[word] = 1\n",
    "\n",
    "house = list()\n",
    "for key, val in wordcount.items():\n",
    "    house.append((val, key) )\n",
    "\n",
    "house.sort(reverse=True)\n",
    "# print top 5\n",
    "for key, val in house[:5] :\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "How many characters his average sentence is. Also print out a copy of the longest sentence and the shortest sentence in The Shunned House."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest sentence: \n",
      "A weak, \n",
      "filtered glow from the rain-harassed street-lamps outside, and a feeble \n",
      "phosphorescence from the detestable fungi within, showed the dripping \n",
      "stone of the walls, from which all traces of whitewash had vanished; \n",
      "the dank, fetid and mildew-tainted hard earth floor with its obscene \n",
      "fungi; the rotting remains of what had been stools, chairs, and tables, \n",
      "and other more shapeless furniture; the heavy planks and massive beams \n",
      "of the ground floor overhead; the decrepit plank door leading to bins \n",
      "and chambers beneath other parts of the house; the crumbling stone \n",
      "staircase with ruined wooden hand-rail; and the crude and cavernous \n",
      "fireplace of blackened brick where rusted iron fragments revealed the \n",
      "past presence of hooks, andirons, spit, crane, and a door to the Dutch \n",
      "oven--these things, and our austere cot and camp chairs, and the heavy \n",
      "and intricate destructive machinery we had brought.\n",
      "\n",
      "shortest sentence: \n",
      "The horror has gone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ryanj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "text = ''.join(open('shunned_house.txt', 'r').read())\n",
    "\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "print('longest sentence: ')\n",
    "print(max(sentences, key = len))\n",
    "print()\n",
    "print('shortest sentence: ')\n",
    "print(min(sentences, key = len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Square roots\n",
    "\n",
    "Write a script that takes a number and finds its square root within .001 accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.001219512195122\n"
     ]
    }
   ],
   "source": [
    "def squareroot(number, epsilon):\n",
    "#condition check\n",
    "    if number == '1':\n",
    "        return 1\n",
    "    elif number <= 0:\n",
    "        print('Positive Numbers Only' )\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    prev_estimate = number/2\n",
    "\n",
    "    while True:\n",
    "        #each itearation, calculate a new estimate\n",
    "        new_estimate = (prev_estimate + number/prev_estimate)/2\n",
    "        \n",
    "        #check the difference between  square of new_estimate and number\n",
    "        if abs(new_estimate * new_estimate - number) < epsilon:\n",
    "            return prev_estimate\n",
    "\n",
    "        #if not good enough, use it to make another estimate\n",
    "        prev_estimate = new_estimate\n",
    "\n",
    "#call the function, change 16 to a #    \n",
    "print(squareroot(16,1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vowel Squares\n",
    "\n",
    "This is a bit of a 'classic' problem. Give a two-dimensional matrix of letters. Analyze said matrix to see if within it there exists a 2 by 2 grid of all vowels. If so, print out the members of that grid; if not, print out \"No match found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o e\n",
      "i a\n"
     ]
    }
   ],
   "source": [
    "# columns, nothing but columns\n",
    "'''import pandas as pd\n",
    "letters = [['a', 'j', 'k', 'e', 'i'], ['b', 'o', 'e', 'n', 'a'], ['u', 'i', 'a', 'z', 'i'] ]\n",
    "A = ['a', 'j', 'k', 'e', 'i']\n",
    "B = ['b', 'o', 'e', 'n', 'a']\n",
    "C = ['u', 'i', 'a', 'z', 'i']\n",
    "\n",
    "l = {'A': A, 'B': B, 'C':C}\n",
    "l\n",
    "{'A': ['a', 'j', 'k', 'e', 'i'], 'B': ['b', 'o', 'e', 'n', 'a'], 'C': ['u', 'i', 'a', 'z', 'i']}\n",
    "\n",
    "df = pd.DataFrame(l,columns=['A','B','C'])\n",
    "print(df)'''\n",
    "\n",
    "# NO!\n",
    "'''letters = [['a', 'j', 'k', 'e', 'i'], ['b', 'o', 'e', 'n', 'a'], ['u', 'i', 'a', 'z', 'i'] ]\n",
    "flattened = []\n",
    "for row in letters:\n",
    "    for i in row:\n",
    "        flattened.append(i)\n",
    "print(flattened)'''\n",
    "\n",
    "# close, returns the top-left position (row-column) of the square\n",
    "'''letters = [['a', 'j', 'k', 'e', 'i'], ['b', 'o', 'e', 'n', 'a'], ['u', 'i', 'a', 'z', 'i'] ]\n",
    "\n",
    "f = \\\n",
    "lambda m:([(y,x)for y in range(len(m)-1)for x in range(len(m[y])-1)if{*(m[y][x:x+2]+m[y+1][x:x+2])}<{*'aeiou'}]+['not found'])[0]\n",
    "\n",
    "print(f(['ajkei', 'boena', 'uiazi']))'''\n",
    "\n",
    "# try again, line 38&39: no go\n",
    "'''def f(m):\n",
    "    for y in range(len(m)-1):\n",
    "        for x in range(len(m[y])-1):\n",
    "            block = {m[y][x],m[y][x+1],m[y+1][x],m[y+1][x+1]}\n",
    "            if (block < {*'aeiou'}):\n",
    "                return (y,x)\n",
    "            return 'Not Found'\n",
    "print(f(['ajkei', 'boena', 'uiazi']))'''\n",
    "\n",
    "# Jim's way *hint\n",
    "letters = [['a', 'j', 'k', 'e', 'i'], ['b', 'o', 'e', 'n', 'a'], ['u', 'i', 'a', 'z', 'i'] ]\n",
    "vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "x = 0\n",
    "y = 0\n",
    "\n",
    "while y <len(letters)-1:\n",
    "    while x <len(letters[y])-1:\n",
    "        if (letters[y][x] in vowels\n",
    "            and letters[y][x+1] in vowels\n",
    "            and letters[y+1][x] in vowels\n",
    "            and letters[y+1][x+1] in vowels):\n",
    "            #output goes here\n",
    "            # print('YES') added for help\n",
    "            print(letters[y][x], letters [y][x+1])\n",
    "            print(letters[y+1][x], letters [y+1][x+1])\n",
    "        x = x +1\n",
    "    y = y +1\n",
    "    x= 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
