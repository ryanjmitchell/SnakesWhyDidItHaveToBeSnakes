{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Iteration & data parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Is GIS really *the best*?\n",
    "\n",
    "### Part 1\n",
    "In the files repository, you'll find a file called `GIS_is_the_best.txt`. You're going to open that file and count the **total** number of words in it.\n",
    "\n",
    "There are a few approaches to this. You can load the file directly from the web (which we'll cover in a later lab, but if you feel like diving in, check out this [stack overflow discussion](https://stackoverflow.com/questions/1393324/in-python-given-a-url-to-a-text-file-what-is-the-simplest-way-to-read-the-cont) or [this module](http://docs.python-requests.org/en/master/). I find the latter easier to work with, but your mileage may vary). **Alternatively**, simply move the file to a local directory and open it like so:\n",
    "\n",
    "```python\n",
    "with open('file location', 'r') as file:\n",
    "    #do some stuff\n",
    "```\n",
    "\n",
    "Then, you need to count the total number of words used.\n",
    "A few hints for this:\n",
    "1. Here's a nice [tutorial](https://www.pythonforbeginners.com/files/reading-and-writing-files-in-python) on dealing with text files.\n",
    "2. Remember list comprehension: how are you going to count words?\n",
    "3. the .upper(), .lower(), and .split() methods all might be useful.\n",
    "\n",
    "#### In summary, your next cell should load up the text file and print out the total number of words in it (it should be 28,177).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28177\n"
     ]
    }
   ],
   "source": [
    "z = 0\n",
    "\n",
    "#First, I need to open the file\n",
    "file = open('GIS_is_the_best.txt', 'r')\n",
    "\n",
    "#Now I need to read it...\n",
    "text = file.read()\n",
    "for i in text.split():\n",
    "    z +=1\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Now it's time to find out what the most common word in that file is. This is a fairly fundamental task of parsing data, so it's good practice (also, I'll ask you to do it again in a slightly more complicated way below). \n",
    "\n",
    "Open the file again and, *this time*, return the most common words **and** how many times it has been used.\n",
    "\n",
    "There's one additional thing to note: capitalization doesn't matter. So, GIS, gis, and Gis should all be counted the same. Similarly, Geospatial and geospatial would be the same. Here, the .upper() or .lower() method can help you.\n",
    "\n",
    "#### In summary, your next cell should output the most common word in the text file and how many times it appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geographic 7545\n",
      "information 7545\n"
     ]
    }
   ],
   "source": [
    "# open file\n",
    "file = open('GIS_is_the_best.txt', 'r')\n",
    "wordcount={}\n",
    "    # lower case, & split into list\n",
    "for word in file.read().lower().split():\n",
    "    if word not in wordcount:\n",
    "        # add  word to wordCounter dictionary\n",
    "        wordcount[word] = 1\n",
    "    else:\n",
    "        # update count if word in dictionary\n",
    "        wordcount[word] += 1\n",
    "x = 0\n",
    "for word in wordcount:\n",
    "    if wordcount[word] >x:\n",
    "        y = word\n",
    "        x = wordcount[word]\n",
    "    elif wordcount[word] ==x:\n",
    "        p = word\n",
    "        q = wordcount [word]\n",
    "# print words and count\n",
    "'''for key in wordcount.keys():\n",
    "  print (\"%s %s \" %(key , wordcount[key]))'''\n",
    "if x > q:\n",
    "    print(y,x)\n",
    "if x == q:\n",
    "    print(y,x)\n",
    "    print(p,q)\n",
    "file.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: A love of Lovecraft\n",
    "\n",
    "Ok, first, let's get it out of the way: H.P. Lovecraft was a disgusting racist. We're using this text because it's in the public domain and uses a lot of unique words, but let's not take our eyes off the prize; this is not an endorsement of the author.\n",
    "\n",
    "With that out of the way, you'll find a .txt copy of *The Shunned House* in the same files repository where you found this lab, [here](https://github.com/UWTMGIS/GIS501_w19_files). Just like before, you can pull the files down locally or (try to) access them through the web (which will be covered in detail in a later lab).\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Here, I want you to count the **number of unique words** in the text. \n",
    "A few directions:\n",
    "1. Case **does not** matter - so 'Whisker' should be the same as 'whisker.'\n",
    "2. Make sure you strip out punctuation - otherwise 'whisker?' and 'whisker!' will come back as different words.\n",
    "3. Plurals are different words in this exercise - 'whiskers' and 'whisker' count separately.\n",
    "\n",
    "A few hints:\n",
    "1. Check out the [collections](https://docs.python.org/2/library/collections.html#collections) module.\n",
    "2. One way to do this would be to create a dictionary of each word and then check the dictionaries length.\n",
    "3. You should get around 3,000 words depending on what assumptions you bake into this. There's no austere 'right' answer as the directions are a bit opaque intentionally (design decisions matter!).\n",
    "\n",
    "#### In summary, your next cell should output how many unique words Lovecraft uses in the copy of the Shunned House I have provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2994\n"
     ]
    }
   ],
   "source": [
    "# dictionary\n",
    "wordcount = {}\n",
    "# open file\n",
    "with open('shunned_house.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "# remove punc\n",
    "for char in '.,?!\":;-_%&*$':\n",
    "    text = text.replace(char,' ')\n",
    "# lower, split, & count\n",
    "for word in text.lower().split():\n",
    "    if word in wordcount:\n",
    "        wordcount[word] += 1\n",
    "    else:\n",
    "        wordcount[word] = 1\n",
    "\n",
    "print(len(wordcount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Excluding prepositions ('from,' 'the,' 'an', 'with', 'a', etc.) what are the five most frequently used words in *The Shunned House* and how many times does each appear?\n",
    "\n",
    "#### In summary, your next cell should output the five most common non-prepositions in the text provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 which\n",
      "58 house\n",
      "42 street\n",
      "31 harris\n",
      "30 there\n"
     ]
    }
   ],
   "source": [
    "# dictionary\n",
    "wordcount = {}\n",
    "prepositions = ['from','the','an','with','a','that','in','to']\n",
    "# open file\n",
    "with open('shunned_house.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "# remove punc\n",
    "    for char in '.,?!\":;-_%&*$':\n",
    "        text = text.replace(char,' ')\n",
    "# lower, split, & count\n",
    "    for word in text.lower().split():\n",
    "        if len(word) > 3 and word in wordcount:\n",
    "            wordcount[word] += 1\n",
    "        elif word not in prepositions:\n",
    "            wordcount[word] = 1\n",
    "\n",
    "house = list()\n",
    "for key, val in wordcount.items():\n",
    "    house.append((val, key) )\n",
    "\n",
    "house.sort(reverse=True)\n",
    "# print top 5\n",
    "for key, val in house[:5] :\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "Ok, last Lovecraft; I promise.\n",
    "\n",
    "Last time, we counted the words he loved to use and how he used them. But, Lovecraft is also known for his lugubrious sentences, the long-winding means by which he tells us his terrible tales. I’m interested in how many characters his average sentence is. I’d also like a printed copy of the longest sentence and the shortest sentence in The Shunned House.\n",
    "\n",
    "Think about how you opened the file, read it, and parsed it into a list last time… *What means do you have to count the character length of objects? What format do those objects have to be?* Etc.\n",
    "\n",
    "This question will help you think about ways to parse through and iterate over different types of data sets (in this case a text file).\n",
    "\n",
    "Hint: In the past, some students have used [nltk](https://pythonspot.com/category/nltk/) to solve this problem; **it is not necessary**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longest sentence: \n",
      "A weak, \n",
      "filtered glow from the rain-harassed street-lamps outside, and a feeble \n",
      "phosphorescence from the detestable fungi within, showed the dripping \n",
      "stone of the walls, from which all traces of whitewash had vanished; \n",
      "the dank, fetid and mildew-tainted hard earth floor with its obscene \n",
      "fungi; the rotting remains of what had been stools, chairs, and tables, \n",
      "and other more shapeless furniture; the heavy planks and massive beams \n",
      "of the ground floor overhead; the decrepit plank door leading to bins \n",
      "and chambers beneath other parts of the house; the crumbling stone \n",
      "staircase with ruined wooden hand-rail; and the crude and cavernous \n",
      "fireplace of blackened brick where rusted iron fragments revealed the \n",
      "past presence of hooks, andirons, spit, crane, and a door to the Dutch \n",
      "oven--these things, and our austere cot and camp chairs, and the heavy \n",
      "and intricate destructive machinery we had brought.\n",
      "\n",
      "shortest sentence: \n",
      "The horror has gone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ryanj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "text = ''.join(open('shunned_house.txt', 'r').read())\n",
    "\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "print('longest sentence: ')\n",
    "print(max(sentences, key = len))\n",
    "print()\n",
    "print('shortest sentence: ')\n",
    "print(min(sentences, key = len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Square roots\n",
    "\n",
    "Write a script that takes a number and finds its square root within .001 accuracy. **Do not use any built in commands to find the square root, write the algorithm yourself (in other words, do not use `sqrt()` or `x**(1/2)` or the like)**\n",
    "\n",
    "Pay attention to how many iterations your solution takes. Try to minimize it. There is a 'best' solution here, but try not to look it up; this is a chance to think through how you split apart and search through data sets (in this case numbers).\n",
    "\n",
    "Hint: This isn't dissimilar to how you would guess a random number. Think about what the 'high' and 'low' values might be and how you can adjust each iteratively.\n",
    "\n",
    "#### In summary, your next cell asks the user for a number and then returns that numbers square root within .001 accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.001219512195122\n"
     ]
    }
   ],
   "source": [
    "def squareroot(number, epsilon):\n",
    "#condition check\n",
    "    if number == '1':\n",
    "        return 1\n",
    "    elif number <= 0:\n",
    "        print('Positive Numbers Only' )\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    prev_estimate = number/2\n",
    "\n",
    "    while True:\n",
    "        #each itearation, calculate a new estimate\n",
    "        new_estimate = (prev_estimate + number/prev_estimate)/2\n",
    "        \n",
    "        #check the difference between  square of new_estimate and number\n",
    "        if abs(new_estimate * new_estimate - number) < epsilon:\n",
    "            return prev_estimate\n",
    "\n",
    "        #if not good enough, use it to make another estimate\n",
    "        prev_estimate = new_estimate\n",
    "\n",
    "#call the function, change 16 to a #    \n",
    "print(squareroot(16,1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Vowel Squares\n",
    "\n",
    "This is a bit of a 'classic' problem. I'm going to give you a two-dimensional matrix of letters. You need to analyze said matrix to see if within it there exists a 2 by 2 grid of all vowels (hint: there is). If so, you print out the members of that grid; if not, you print out \"No match found.\"\n",
    "\n",
    "In other words, I'm going to give you something like this:\n",
    "\n",
    "a b c d e f\n",
    "\n",
    "g h i j k l\n",
    "\n",
    "**a a** k e v o\n",
    "\n",
    "**i o** e r p z\n",
    "\n",
    "And, you'd need to return a a i o.\n",
    "\n",
    "**THIS IS HARD**. Work together! Don't look up a solution, do think about how you might parse through this. There are many solutions, one I might consider is creating a new matrix that simple records if something is a vowel or not (i.e. a 1 value for a vowel, a 0 for not, etc.). *Partial credit is possible*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o e\n",
      "i a\n"
     ]
    }
   ],
   "source": [
    "# columns, nothing but columns\n",
    "'''import pandas as pd\n",
    "letters = [['a', 'j', 'k', 'e', 'i'], ['b', 'o', 'e', 'n', 'a'], ['u', 'i', 'a', 'z', 'i'] ]\n",
    "A = ['a', 'j', 'k', 'e', 'i']\n",
    "B = ['b', 'o', 'e', 'n', 'a']\n",
    "C = ['u', 'i', 'a', 'z', 'i']\n",
    "\n",
    "l = {'A': A, 'B': B, 'C':C}\n",
    "l\n",
    "{'A': ['a', 'j', 'k', 'e', 'i'], 'B': ['b', 'o', 'e', 'n', 'a'], 'C': ['u', 'i', 'a', 'z', 'i']}\n",
    "\n",
    "df = pd.DataFrame(l,columns=['A','B','C'])\n",
    "print(df)'''\n",
    "\n",
    "# NO!\n",
    "'''letters = [['a', 'j', 'k', 'e', 'i'], ['b', 'o', 'e', 'n', 'a'], ['u', 'i', 'a', 'z', 'i'] ]\n",
    "flattened = []\n",
    "for row in letters:\n",
    "    for i in row:\n",
    "        flattened.append(i)\n",
    "print(flattened)'''\n",
    "\n",
    "# close, returns the top-left position (row-column) of the square\n",
    "'''letters = [['a', 'j', 'k', 'e', 'i'], ['b', 'o', 'e', 'n', 'a'], ['u', 'i', 'a', 'z', 'i'] ]\n",
    "\n",
    "f = \\\n",
    "lambda m:([(y,x)for y in range(len(m)-1)for x in range(len(m[y])-1)if{*(m[y][x:x+2]+m[y+1][x:x+2])}<{*'aeiou'}]+['not found'])[0]\n",
    "\n",
    "print(f(['ajkei', 'boena', 'uiazi']))'''\n",
    "\n",
    "# try again, line 38&39: no go\n",
    "'''def f(m):\n",
    "    for y in range(len(m)-1):\n",
    "        for x in range(len(m[y])-1):\n",
    "            block = {m[y][x],m[y][x+1],m[y+1][x],m[y+1][x+1]}\n",
    "            if (block < {*'aeiou'}):\n",
    "                return (y,x)\n",
    "            return 'Not Found'\n",
    "print(f(['ajkei', 'boena', 'uiazi']))'''\n",
    "\n",
    "# Jim's way *hint\n",
    "letters = [['a', 'j', 'k', 'e', 'i'], ['b', 'o', 'e', 'n', 'a'], ['u', 'i', 'a', 'z', 'i'] ]\n",
    "vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "x = 0\n",
    "y = 0\n",
    "\n",
    "while y <len(letters)-1:\n",
    "    while x <len(letters[y])-1:\n",
    "        if (letters[y][x] in vowels\n",
    "            and letters[y][x+1] in vowels\n",
    "            and letters[y+1][x] in vowels\n",
    "            and letters[y+1][x+1] in vowels):\n",
    "            #output goes here\n",
    "            # print('YES') added for help\n",
    "            print(letters[y][x], letters [y][x+1])\n",
    "            print(letters[y+1][x], letters [y+1][x+1])\n",
    "        x = x +1\n",
    "    y = y +1\n",
    "    x= 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
